{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyP79VAXWnHPpiB+KaFlJ+ak"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Extract offensive images from another dataset"],"metadata":{"id":"CHfKavdQ8_dg"}},{"cell_type":"markdown","source":["https://www.kaggle.com/datasets/parthplc/facebook-hateful-meme-dataset"],"metadata":{"id":"EPD9-nvyyQup"}},{"cell_type":"code","source":["!ls ./facebook-hateful-meme-dataset/\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FK-AstLG0_zr","executionInfo":{"status":"ok","timestamp":1725814333848,"user_tz":-480,"elapsed":378,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}},"outputId":"54e102a6-16c5-4510-a386-5486a7fb08b9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access './facebook-hateful-meme-dataset/': No such file or directory\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":42},"id":"wO8LccAaxbqM","outputId":"b192cc92-cc36-4c0b-bfdf-3ed06ed5e050"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c79aef18-2c81-4506-a0e9-25a3a5991e01\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c79aef18-2c81-4506-a0e9-25a3a5991e01\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}}],"source":["\n","from google.colab import files\n","uploaded = files.upload()\n","\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","!pip install kaggle\n","!kaggle datasets download -d parthplc/facebook-hateful-meme-dataset\n","\n","!unzip facebook-hateful-meme-dataset.zip -d facebook-hateful-meme-dataset\n","\n","# Load the JSONL training file (train.jsonl) for text-based data\n","import pandas as pd\n","import json\n","\n","# Load training data from JSONL\n","# Correct path to train.jsonl\n","train_data = []\n","with open('./facebook-hateful-meme-dataset/data/train.jsonl', 'r') as f:\n","    for line in f:\n","        train_data.append(json.loads(line))\n","\n","# Convert to DataFrame\n","train_df = pd.DataFrame(train_data)\n","\n","# View first few rows of the DataFrame\n","train_df.head()\n","\n","\n","# Load images\n","import os\n","from PIL import Image\n","\n","# Set the base directory for images\n","image_dir = './facebook-hateful-meme-dataset/data/'\n","\n","# Load and display the first image\n","sample_image = Image.open(os.path.join(image_dir, train_df.iloc[0]['img']))\n","sample_image.show()\n","\n","\n"]},{"cell_type":"code","source":["# Filter the DataFrame where label == 1\n","offensive_images = train_df[train_df['label'] == 1].head(20)\n","\n","# Set up a figure for displaying multiple images\n","plt.figure(figsize=(20, 10))\n","\n","# Loop through the first 20 offensive images and display them\n","for i, (index, row) in enumerate(offensive_images.iterrows()):\n","    plt.subplot(4, 5, i + 1)  # 4 rows, 5 columns grid\n","    img_path = os.path.join(image_dir, row['img'])\n","    img = Image.open(img_path)\n","    plt.imshow(img)\n","    plt.axis('off')  # Hide axis\n","\n","plt.show()\n"],"metadata":{"id":"JuKnfUO92BOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show descriptive statistics for the dataset\n","train_df.head()\n"],"metadata":{"id":"KiAVqbrT2KRy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","train_df.info()\n"],"metadata":{"id":"KBbfkbOZ2KPX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.describe(include='all')"],"metadata":{"id":"lsmryyWX2KM4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df['label'].value_counts()"],"metadata":{"id":"0HzUPb5o3bA6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(train_df.head(2))"],"metadata":{"id":"S7VTxMb030Ok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check for NaN values in the 'text' column\n","missing_texts = train_df['text'].isna().sum()\n","print(f\"Number of missing (NaN) values in 'text' column: {missing_texts}\")\n","\n","# Check for empty strings in the 'text' column\n","empty_texts = (train_df['text'] == '').sum()\n","print(f\"Number of empty strings in 'text' column: {empty_texts}\")\n"],"metadata":{"id":"nixAyhUOHlfu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import shutil\n","import os\n","import pandas as pd\n","\n","# Set Google Drive directory\n","output_dir = '/content/drive/MyDrive/curate138dataset/offensive_images/'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Filter 150 entries where label = 1\n","offensive_images = train_df[train_df['label'] == 1].head(150)\n","\n","# Initialize list to store CSV data\n","csv_data = []\n","\n","# Loop through the entries and copy images to Google Drive, while collecting data for CSV\n","for i, row in offensive_images.iterrows():\n","    img_path = os.path.join(image_dir, row['img'])\n","    output_path = os.path.join(output_dir, row['img'].split('/')[-1])\n","    shutil.copy(img_path, output_path)\n","\n","    # Add data for CSV\n","    csv_data.append({\n","        'image_name': row['img'].split('/')[-1],\n","        'text': row['text'],\n","        'label': row['label'],\n","        'image_path': output_path\n","    })\n","\n","# Create DataFrame for CSV\n","df_csv = pd.DataFrame(csv_data)\n","\n","# Save DataFrame to CSV\n","csv_path = '/content/drive/MyDrive/curate138dataset/offensive_images_text.csv'\n","df_csv.to_csv(csv_path, index=False)\n","\n","print(f'Successfully copied {len(offensive_images)} images and saved CSV to {csv_path}')\n"],"metadata":{"id":"VPJXAoLp5yeZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"0LByucya9Is8"}},{"cell_type":"markdown","source":[],"metadata":{"id":"ad74uSOL9KYg"}},{"cell_type":"markdown","source":["## Optical Character Recognition (OCR)\n","to extract text from the images and form a CSV with the columns image_name, sentence, label, and image_path"],"metadata":{"id":"yIHl1Cns8r-Q"}},{"cell_type":"code","source":["!apt-get install tesseract-ocr\n","!pip install pytesseract Pillow\n"],"metadata":{"id":"4ky_QRP88nRb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pytesseract\n","import pandas as pd\n","import os\n","from PIL import Image\n","\n","# Initialize an empty list to store the data\n","data = []\n","\n","# Path to the offensive images folder\n","offensive_images_dir = '/content/drive/MyDrive/curate138dataset/offensive_images/'\n","\n","# Loop over images in the folder\n","for img_name in os.listdir(offensive_images_dir):\n","    if img_name.endswith('.png'):\n","        img_path = os.path.join(offensive_images_dir, img_name)\n","        img = Image.open(img_path)\n","\n","        # Extract text using pytesseract\n","        sentence = pytesseract.image_to_string(img)\n","\n","        # Append data as a dictionary\n","        data.append({\n","            'image_name': img_name,\n","            'sentence': sentence.strip(),  # Clean text\n","            'label': 1,  # Set label as 1 for offensive images\n","            'image_path': img_path\n","        })\n","\n","# Convert the list of dictionaries to a DataFrame\n","df = pd.DataFrame(data)\n","\n","# Save DataFrame to CSV\n","df.to_csv('/content/drive/MyDrive/curate138dataset/offensive_images_text.csv', index=False)\n","\n","print(\"CSV file saved successfully.\")\n"],"metadata":{"id":"Mn68sgyF8ylD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Did not proceed with OCR as a lot of text were lost in the process. I will retain accurate text using the data provided."],"metadata":{"id":"pJlZ94DCMQI6"}},{"cell_type":"code","source":[],"metadata":{"id":"WOX0otFfMjTn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","# Path to the offensive images folder\n","offensive_images_dir = '/content/drive/MyDrive/curate138dataset/offensive_images/'\n","\n","# Get the list of PNG images in the folder\n","image_files = [f for f in os.listdir(offensive_images_dir) if f.endswith('.png')]\n","\n","# Display the first few images\n","plt.figure(figsize=(20, 10))\n","\n","for i, img_name in enumerate(image_files[:20]):  # Show first 20 images\n","    img_path = os.path.join(offensive_images_dir, img_name)\n","\n","    try:\n","        img = Image.open(img_path)\n","        plt.subplot(4, 5, i + 1)  # 4x5 grid\n","        plt.imshow(img)\n","        plt.axis('off')\n","    except Exception as e:\n","        print(f\"Could not open {img_name}: {e}\")\n","\n","plt.show()\n"],"metadata":{"id":"sxoWeC2c_h1R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"5fK5vaApLWCD"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the CSV file into a DataFrame\n","csv_path = '/content/drive/MyDrive/curate138dataset/offensive_images_text.csv'\n","df = pd.read_csv(csv_path)\n","\n","# View the first 5 rows of the DataFrame\n","df.head()\n"],"metadata":{"id":"Ubau-iRRLgsW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()\n"],"metadata":{"id":"kGc7MLnKLg0B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loading curated images"],"metadata":{"id":"-67ek0ur71Ly"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yNMBMUk5--Sw","executionInfo":{"status":"ok","timestamp":1725814579585,"user_tz":-480,"elapsed":2892,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}},"outputId":"b86d3958-7bfc-43c3-d23f-70d22f296b7f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Manually looked through the images and remove images that are very vague to refine data for combination."],"metadata":{"id":"L_AtQcA2Gk5z"}},{"cell_type":"code","source":["import os\n","\n","# List of image names to remove\n","images_to_remove = [\n","    '93072.png', '92016.png', '91704.png', '63710.png', '54817.png',\n","    '36081.png', '34791.png', '02849.png', '01524.png', '06483.png', '08593.png'\n","]\n","\n","# Path to the offensive images folder\n","offensive_images_dir = '/content/drive/MyDrive/curate138dataset/offensive_images/'\n","\n","# Remove images\n","for img_name in images_to_remove:\n","    img_path = os.path.join(offensive_images_dir, img_name)\n","    if os.path.exists(img_path):\n","        os.remove(img_path)\n","        print(f\"Removed {img_name}\")\n","    else:\n","        print(f\"{img_name} not found\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SseM3UnP8yim","executionInfo":{"status":"ok","timestamp":1725814582544,"user_tz":-480,"elapsed":400,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}},"outputId":"7d71df08-8ac7-4016-9cdb-5d92813ae943"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["93072.png not found\n","92016.png not found\n","91704.png not found\n","63710.png not found\n","54817.png not found\n","36081.png not found\n","34791.png not found\n","02849.png not found\n","01524.png not found\n","06483.png not found\n","08593.png not found\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Path to the CSV file\n","csv_path = '/content/drive/MyDrive/curate138dataset/offensive_images_text.csv'\n","\n","# Load the CSV into a DataFrame\n","df = pd.read_csv(csv_path)\n","\n","# Filter out the rows where image_name matches the ones to remove\n","df = df[~df['image_name'].isin(images_to_remove)]\n","\n","# Save the updated DataFrame back to CSV\n","df.to_csv(csv_path, index=False)\n","\n","print(\"Updated CSV file saved.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qTVw41kKGyP2","executionInfo":{"status":"ok","timestamp":1725814586966,"user_tz":-480,"elapsed":371,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}},"outputId":"be7e1c66-ba91-475e-bac9-06139325c177"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated CSV file saved.\n"]}]},{"cell_type":"code","source":["# List rows where 'sentence' is NaN or empty\n","empty_sentences = df[df['text'].isna() | (df['text'] == '')]\n","\n","# Display the rows with missing or empty sentences\n","empty_sentences\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"id":"FsLj_00OHFZj","executionInfo":{"status":"ok","timestamp":1725814592496,"user_tz":-480,"elapsed":360,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}},"outputId":"e3b48060-a28b-400f-e643-d3a71c5b0b2e"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: [image_name, text, label, image_path]\n","Index: []"],"text/html":["\n","  <div id=\"df-cb3d3a0b-da40-4f34-9b4e-8193014ff1b9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>image_path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb3d3a0b-da40-4f34-9b4e-8193014ff1b9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cb3d3a0b-da40-4f34-9b4e-8193014ff1b9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cb3d3a0b-da40-4f34-9b4e-8193014ff1b9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_3a4e76f1-d54e-40b5-afd1-204379c17621\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('empty_sentences')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_3a4e76f1-d54e-40b5-afd1-204379c17621 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('empty_sentences');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"empty_sentences","repr_error":"Out of range float values are not JSON compliant: nan"}},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["# To match the main dataset, I will proceed to standardise and preprocess"],"metadata":{"id":"hJWXrFthMwz7"}},{"cell_type":"code","source":["# Load the current dataset\n","csv_path = '/content/drive/MyDrive/curate138dataset/offensive_images_text.csv'\n","df = pd.read_csv(csv_path)\n","\n","# Rename\n","df_standardized = df.rename(columns={\n","    'text': 'sentence',\n","})\n","\n","# Rearrange columns to match the desired structure: image_name, sentence, label\n","df_standardized = df_standardized[['image_name', 'sentence', 'label', 'image_path']]\n","\n","# View the first few rows of the standardized DataFrame\n","df_standardized.head()\n","\n","# Save the standardized dataset to a new CSV file\n","df_standardized.to_csv('/content/drive/MyDrive/curate138dataset/standardized_offensive_images_text.csv', index=False)\n","\n","print(\"Dataset standardized and saved successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MI23v37aKNBD","executionInfo":{"status":"ok","timestamp":1725814599456,"user_tz":-480,"elapsed":562,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}},"outputId":"5da3ecfd-b5a1-428e-f0c1-82550ce63117"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset standardized and saved successfully.\n"]}]},{"cell_type":"code","source":["# View the first few rows of the DataFrame\n","df_standardized.head()\n","\n","# To view the entire DataFrame, you can simply use:\n","print(df_standardized)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uCN1tA_EN8-Q","executionInfo":{"status":"ok","timestamp":1725814603273,"user_tz":-480,"elapsed":369,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}},"outputId":"f43eaa84-58d4-481b-c4da-5ec74ddc1c7f"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["    image_name                                           sentence  label  \\\n","0    79351.png                           jew mad? get fuhrerious!      1   \n","1    25489.png   brother... a day without a blast is a day wasted      1   \n","2    72640.png  is bribing muslims for liberal votes justin tr...      1   \n","3    93547.png  d.j. osama spin laden droppin' beats like the ...      1   \n","4    74386.png  we said we would never forget why are you voti...      1   \n","..         ...                                                ...    ...   \n","134  20759.png      this steak is so black it stole my television      1   \n","135  62435.png                 wing wing wing herro? thats racist      1   \n","136  62849.png                 cumshot on jewish girl face - 1943      1   \n","137  62081.png  well let me tell you something brother fuck ni...      1   \n","138  85923.png  ford owner blew a rod wasnt talking about his ...      1   \n","\n","                                            image_path  \n","0    /content/drive/MyDrive/curate138dataset/offens...  \n","1    /content/drive/MyDrive/curate138dataset/offens...  \n","2    /content/drive/MyDrive/curate138dataset/offens...  \n","3    /content/drive/MyDrive/curate138dataset/offens...  \n","4    /content/drive/MyDrive/curate138dataset/offens...  \n","..                                                 ...  \n","134  /content/drive/MyDrive/curate138dataset/offens...  \n","135  /content/drive/MyDrive/curate138dataset/offens...  \n","136  /content/drive/MyDrive/curate138dataset/offens...  \n","137  /content/drive/MyDrive/curate138dataset/offens...  \n","138  /content/drive/MyDrive/curate138dataset/offens...  \n","\n","[139 rows x 4 columns]\n"]}]},{"cell_type":"code","source":["!pip install contractions\n","import contractions\n","import re\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oqz0sBz0PwgB","executionInfo":{"status":"ok","timestamp":1725814486761,"user_tz":-480,"elapsed":3432,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}},"outputId":"99b5e51a-e40a-4cc4-b90e-3d9c7ebed729"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n","Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n","Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n","Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"]}]},{"cell_type":"code","source":["# Standardize texts\n","def pB_sentence(text):\n","    text = contractions.fix(text)  # Expand contractions\n","    text = text.lower()  # Convert to lowercase\n","    # Remove non-alphanumeric characters except for exclamation marks and question marks\n","    text = re.sub(r'[^a-z0-9\\s]', '', text)\n","    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n","    text = text.strip()  # Remove leading and trailing whitespace\n","    return text  # Return the processed text\n","\n","# Apply the basic preprocessing function to the 'sentence' column\n","df_standardized['sentence'] = df_standardized['sentence'].apply(pB_sentence)\n","\n","# Check a few processed sentences\n","print(df_standardized['sentence'].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0UO9a0lfOsPh","executionInfo":{"status":"ok","timestamp":1725814619201,"user_tz":-480,"elapsed":365,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}},"outputId":"e7d2f590-186f-4cff-e70d-89cce8f996e8"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["0                               jew mad get fuhrerious\n","1        brother a day without a blast is a day wasted\n","2    is bribing muslims for liberal votes justin tr...\n","3    dj osama spin laden droppin beats like the twi...\n","4    we said we would never forget why are you voti...\n","Name: sentence, dtype: object\n"]}]},{"cell_type":"markdown","source":["##Image"],"metadata":{"id":"2OKqFlbMQDXa"}},{"cell_type":"code","source":["from PIL import Image\n"],"metadata":{"id":"h_Z9Nz8nkczk","executionInfo":{"status":"ok","timestamp":1725814658893,"user_tz":-480,"elapsed":389,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Function to retrieve image details\n","def get_image_details(image_path):\n","    try:\n","        img = Image.open(image_path)\n","        image_format = img.format  # Get image format\n","        image_size = img.size  # Get image size (width, height)\n","        image_mode = img.mode  # Get image mode\n","        return image_format, image_size, image_mode\n","    except Exception as e:\n","        print(f\"Error processing {image_path}: {e}\")\n","        return None, None, None\n","\n","# Apply the function to get details for each image in the dataset\n","df_standardized['image_format'], df_standardized['image_size'], df_standardized['image_mode'] = zip(*df_standardized['image_path'].apply(get_image_details))\n","# Count the occurrences of each image format\n","image_format_counts = df_standardized['image_format'].value_counts()\n","# Display the counts of each image format\n","print(\"\\nImage format counts:\")\n","print(image_format_counts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pthZZwXtO1Cf","executionInfo":{"status":"ok","timestamp":1725814701424,"user_tz":-480,"elapsed":41200,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}},"outputId":"2de2c69e-9147-4a0c-9e3f-bce02b2a681d"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Image format counts:\n","image_format\n","PNG    139\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["# Check if images are in RGB mode\n","rgb_images = df_standardized[df_standardized['image_mode'] == 'RGB']\n","non_rgb_images = df_standardized[df_standardized['image_mode'] != 'RGB']\n","\n","# Display the count of RGB and non-RGB images\n","print(f\"Number of RGB images: {len(rgb_images)}\")\n","print(f\"Number of non-RGB images: {len(non_rgb_images)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-2IFFMxuO06u","executionInfo":{"status":"ok","timestamp":1725814701424,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}},"outputId":"15e62f54-2e11-4414-9fbe-4bb40b824fc9"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of RGB images: 139\n","Number of non-RGB images: 0\n"]}]},{"cell_type":"code","source":["# Save the processed DataFrame to the CSV file in Google Drive\n","df_standardized.to_csv('/content/drive/MyDrive/curate138dataset/standardized_offensive_images_text.csv', index=False)\n","\n","print(\"CSV file updated successfully.\")\n"],"metadata":{"id":"to2s3TMVO0ln","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725814701425,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yap Qian Hui (Gwen)","userId":"07545595159768354148"}},"outputId":"0abc3c28-67a0-4b91-b96b-b7424fd0de98"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV file updated successfully.\n"]}]}]}